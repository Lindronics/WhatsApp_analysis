{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WhatsApp_analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lindronics/WhatsApp_analysis/blob/master/WhatsApp_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "x8GKIs5fEgLV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# WhatsApp chat protocol analysis\n",
        "\n",
        "This notebook demonstrates a model for author classification of WhatsApp text messages."
      ]
    },
    {
      "metadata": {
        "id": "CFSm7eNaeli-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, if necessary, install all dependencies."
      ]
    },
    {
      "metadata": {
        "id": "1FxwFTsObG-M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !pip install pandas\n",
        "# !pip install spacy\n",
        "# !pip install nltk\n",
        "# !pip install sklearn\n",
        "!pip install eli5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IdbVP-2VBtRc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xL000esgE5lA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load WhatsApp chat protocol\n",
        "\n",
        "Load a WhatsApp chat protocol into the notebook.\n",
        "This is the raw file that gets created when exporting a conversation in WhatsApp."
      ]
    },
    {
      "metadata": {
        "id": "BexdIXpNfGlU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From local file system..."
      ]
    },
    {
      "metadata": {
        "id": "nVSKURNHBwEq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded_files = files.upload()\n",
        "\n",
        "# for name, file in uploaded_files.items():\n",
        "#     print(name, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gIaW2YVWG6QN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "... or from Google Drive."
      ]
    },
    {
      "metadata": {
        "id": "-fcZnuYVF3c8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "path = \"/content/gdrive/My Drive/Analysis/WhatsApp/\"\n",
        "filename = input(\"Name of file: \")\n",
        "\n",
        "# Open file with specified name\n",
        "raw_protocol = list()\n",
        "with open(path + filename, 'r') as f:\n",
        "    \n",
        "    # For each line, split into timestamp, author and message body\n",
        "    for line in f:\n",
        "        splitted = re.compile(\"(.+) \\- (.+?): (.*)\").split(line)[1:-1]\n",
        "        raw_protocol.append(splitted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c4cGSa5UG9Np",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Process into Pandas DataFrame"
      ]
    },
    {
      "metadata": {
        "id": "9WdlF5W0GCQz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "protocol = pd.DataFrame(raw_protocol)\n",
        "protocol.columns = [\"timestamp\", \"author\", \"body\"]\n",
        "protocol = protocol.dropna()\n",
        "protocol = protocol.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Print some information about the data\n",
        "print(\"Size: \", protocol.size)\n",
        "protocol.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yTz-uGARVf6u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Print all authors\n",
        "protocol.author.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "by0vRbJhOvAf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Split into train and test"
      ]
    },
    {
      "metadata": {
        "id": "YGpo_3GUOxXi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_test_split = int(len(protocol) * 0.9)\n",
        "\n",
        "train_protocol = protocol[:train_test_split]\n",
        "test_protocol = protocol[train_test_split:]\n",
        "\n",
        "train_labels = train_protocol.author.tolist()\n",
        "test_labels = test_protocol.author.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QJjp5pzXJ8nR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "metadata": {
        "id": "OkE8j5sbGhxQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.remove_pipe('tagger')\n",
        "nlp.remove_pipe('parser')\n",
        "\n",
        "def tokenize(s):\n",
        "    return nlp(s)\n",
        "\n",
        "def normalize(tokens):\n",
        "    normalized_tokens = list()\n",
        "    for token in tokens:\n",
        "        if not token.is_stop and (token.is_alpha or token.is_digit):\n",
        "            normalized_tokens.append(token.text.lower().strip())\n",
        "    return normalized_tokens\n",
        "\n",
        "def tokenize_normalize(s):\n",
        "    return normalize(tokenize(s))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lAYgbOuaNNS9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Vectorization and Classification"
      ]
    },
    {
      "metadata": {
        "id": "FY80c9RJM-zN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import numpy as np\n",
        "\n",
        "class ItemSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Select pandas DataFrame column\"\"\"\n",
        "\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_dict):\n",
        "        return data_dict[self.key]\n",
        "    \n",
        "class LengthSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Return length of values at DataFrame column\"\"\"\n",
        "\n",
        "    def __init__(self, key):\n",
        "\n",
        "        self.key = key\n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_dict):\n",
        "        lengths = np.array(data_dict[self.key].str.len())\n",
        "        return lengths.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C4EnD_5gNvbz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "vectorizer_params = {\n",
        "#     \"tokenizer\": tokenize_normalize,\n",
        "    \"ngram_range\": (1, 3),\n",
        "}\n",
        "\n",
        "selector = Pipeline([\n",
        "    (\"selector\", ItemSelector(\"body\")),\n",
        "])\n",
        "\n",
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(**vectorizer_params)),\n",
        "    (\"classifier\", LogisticRegression()),\n",
        "])\n",
        "\n",
        "pipeline = make_pipeline(selector, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJ3ltDOGOplS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "\n",
        "pipeline.fit(train_protocol, train_labels)\n",
        "\n",
        "print(\"Elapsed: %f seconds\" % (time.time() - t1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fTdwkPwyUsCU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "3WO4xpp2Ptqu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicted_labels = pipeline.predict(test_protocol)\n",
        "print(classification_report(test_labels, predicted_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pdXatLhnamWN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import eli5\n",
        "\n",
        "features = model.named_steps[\"vectorizer\"].get_feature_names()\n",
        "\n",
        "eli5.show_weights(model.named_steps[\"classifier\"], vec=model.named_steps[\"vectorizer\"], feature_names=features, top=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qaB0Y-i2X_pq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Playground (predict an author)"
      ]
    },
    {
      "metadata": {
        "id": "xGZiL-LWVF70",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from eli5.lime import TextExplainer\n",
        "te = TextExplainer(random_state=42)\n",
        "\n",
        "# Get message to predict\n",
        "input_message = input(\"Message to predict: \")\n",
        "\n",
        "# Convert to DataFrame, so it can be input into the pipeline\n",
        "input_df = pd.DataFrame([input_message])\n",
        "input_df.columns = [\"body\"]\n",
        "\n",
        "print(\"This message is by %s with a probability of %f.\\n\" % (\n",
        "    pipeline.predict(input_df)[0], \n",
        "    max(pipeline.predict_proba(input_df)[0])\n",
        "))\n",
        "\n",
        "te.fit(input_message, model.predict_proba)\n",
        "te.show_prediction()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gsJ8lsPIXK0-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WhatsApp_analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lindronics/WhatsApp_analysis/blob/master/WhatsApp_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8GKIs5fEgLV",
        "colab_type": "text"
      },
      "source": [
        "# WhatsApp chat protocol analysis\n",
        "\n",
        "This notebook demonstrates a model for author classification of WhatsApp text messages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFSm7eNaeli-",
        "colab_type": "text"
      },
      "source": [
        "First, if necessary, install all dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FxwFTsObG-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install pandas\n",
        "# !pip install spacy\n",
        "# !pip install nltk\n",
        "# !pip install sklearn\n",
        "!pip install eli5\n",
        "!pip install emoji"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdbVP-2VBtRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from emoji import demojize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL000esgE5lA",
        "colab_type": "text"
      },
      "source": [
        "## Load WhatsApp chat protocol\n",
        "\n",
        "Load a WhatsApp chat protocol into the notebook.\n",
        "This is the raw file that gets created when exporting a conversation in WhatsApp."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BexdIXpNfGlU",
        "colab_type": "text"
      },
      "source": [
        "From local file system..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVSKURNHBwEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded_files = files.upload()\n",
        "\n",
        "# for name, file in uploaded_files.items():\n",
        "#     print(name, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIaW2YVWG6QN",
        "colab_type": "text"
      },
      "source": [
        "... or from Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fcZnuYVF3c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "path = \"/content/gdrive/My Drive/Analysis/WhatsApp/\"\n",
        "filename = input(\"Name of file: \")\n",
        "\n",
        "\n",
        "# Open file with specified name\n",
        "raw_protocol = list()\n",
        "with open(path + filename, 'r') as f:\n",
        "    \n",
        "    # For each line, split into timestamp, author and message body\n",
        "    for line in f:\n",
        "        splitted = re.compile(\"(.+) \\- (.+?): (.*)\").split(line)[1:-1]\n",
        "        if len(splitted) > 0:\n",
        "            splitted[-1] = demojize(splitted[-1])\n",
        "            raw_protocol.append(splitted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4cGSa5UG9Np",
        "colab_type": "text"
      },
      "source": [
        "### Process into Pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WdlF5W0GCQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "protocol = pd.DataFrame(raw_protocol)\n",
        "protocol.columns = [\"timestamp\", \"author\", \"body\"]\n",
        "protocol = protocol.dropna()\n",
        "protocol = protocol.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Print some information about the data\n",
        "print(\"Size: \", protocol.size)\n",
        "protocol.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTz-uGARVf6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print all authors and class balance\n",
        "protocol.author.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by0vRbJhOvAf",
        "colab_type": "text"
      },
      "source": [
        "### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGpo_3GUOxXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "split = 0.15\n",
        "X_train, X_test, y_train, y_test = train_test_split(protocol[\"body\"], \n",
        "                                                    protocol[\"author\"], \n",
        "                                                    test_size=split, \n",
        "                                                    shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAYgbOuaNNS9",
        "colab_type": "text"
      },
      "source": [
        "## Vectorization and Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TydHVblV4olE",
        "colab_type": "text"
      },
      "source": [
        "### Helper class for extracting POS tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY80c9RJM-zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import numpy as np\n",
        "import spacy\n",
        "    \n",
        "    \n",
        "class POSSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\" Extract POS tags using spaCy \"\"\"\n",
        "    \n",
        "    \n",
        "    def __init__(self):\n",
        "        self.feature_names = set()\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "        self.nlp.remove_pipe('parser')\n",
        "        print(\"Spacy model loaded.\")\n",
        "\n",
        "        \n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    \n",
        "    def transform(self, df):\n",
        "        \n",
        "        def get_pos(doc):\n",
        "            tokens = []\n",
        "            for token in self.nlp(doc):\n",
        "                self.feature_names.add(token.pos_)\n",
        "                tokens.append(token.pos_)\n",
        "            return \" \".join(tokens)\n",
        "                     \n",
        "        pos_tags = df.apply(get_pos)\n",
        "        return pos_tags\n",
        "    \n",
        "    \n",
        "    def get_feature_names(self):\n",
        "        return list(self.feature_names)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2mJS1IO4h4y",
        "colab_type": "text"
      },
      "source": [
        "### Define classification pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4EnD_5gNvbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "\n",
        "vectorizer_params = {\n",
        "    \"ngram_range\": (1, 3),\n",
        "}\n",
        "\n",
        "token_vec = TfidfVectorizer(**vectorizer_params)\n",
        "pos_vec = TfidfVectorizer()\n",
        "\n",
        "\n",
        "# Define classification pipeline\n",
        "model = Pipeline([\n",
        "    (\"features\", FeatureUnion([\n",
        "        (\"tokens\", Pipeline([\n",
        "            (\"vec\", token_vec),\n",
        "        ])),\n",
        "        (\"pos_tags\", Pipeline([\n",
        "            (\"select\", POSSelector()),\n",
        "            (\"vec\", pos_vec),\n",
        "        ]))\n",
        "    ])),\n",
        "    (\"cla\", LinearSVC()),\n",
        "])\n",
        "\n",
        "\n",
        "# Dummy model as baseline\n",
        "dummy_model = Pipeline([\n",
        "    (\"features\", FeatureUnion([\n",
        "        (\"tokens\", Pipeline([\n",
        "            (\"vec\", TfidfVectorizer(**vectorizer_params)),\n",
        "        ])),\n",
        "        (\"pos_tags\", Pipeline([\n",
        "            (\"select\", POSSelector()),\n",
        "            (\"vec\", TfidfVectorizer()),\n",
        "        ]))\n",
        "    ])),\n",
        "    (\"cla\", DummyClassifier(strategy=\"stratified\")),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ3ltDOGOplS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = time.time()\n",
        "\n",
        "\n",
        "# Fit model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Fit dummy model\n",
        "dummy_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"Elapsed: %f seconds\" % (time.time() - t1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTdwkPwyUsCU",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WO4xpp2Ptqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "print(\"Test data\")\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "# print(\"Train data\")\n",
        "# train_predicted_labels = pipeline.predict(X_train)\n",
        "# print(classification_report(y_train, train_predicted_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT7KHwpll_Br",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "print(\"Test data\")\n",
        "y_pred = dummy_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdXatLhnamWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import eli5\n",
        "\n",
        "\n",
        "features = token_vec.get_feature_names() + pos_vec.get_feature_names()\n",
        "eli5.show_weights(model.named_steps[\"cla\"], feature_names=features, top=40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaB0Y-i2X_pq",
        "colab_type": "text"
      },
      "source": [
        "## Playground (predict an author)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGZiL-LWVF70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from eli5.lime import TextExplainer\n",
        "te = TextExplainer(random_state=42)\n",
        "\n",
        "\n",
        "# Get message to predict\n",
        "input_message = input(\"Message to predict: \")\n",
        "\n",
        "\n",
        "# Convert to DataFrame, so it can be input into the pipeline\n",
        "input_df = pd.Series([input_message])\n",
        "\n",
        "\n",
        "print(\"This message is by %s with a probability of %f.\\n\" % (\n",
        "    pipeline.predict(input_df)[0], \n",
        "    max(pipeline.predict_proba(input_df)[0])\n",
        "))\n",
        "\n",
        "\n",
        "te.fit(input_message, model.predict_proba)\n",
        "te.show_prediction()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsJ8lsPIXK0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
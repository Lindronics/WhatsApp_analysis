{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WhatsApp_analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lindronics/WhatsApp_analysis/blob/master/WhatsApp_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8GKIs5fEgLV",
        "colab_type": "text"
      },
      "source": [
        "# WhatsApp chat protocol author classification (NLP)\n",
        "\n",
        "### Introduction\n",
        "This notebook demonstrates a model for author classification of WhatsApp text messages.\n",
        "\n",
        "### Model\n",
        "Classification methods used are LinearSVC with sklearn and a Deep-Feed-Forward Network with tf-keras.\n",
        "Furthermore, the model incorporates POS tags using spaCy.\n",
        "\n",
        "### Results\n",
        "With a non-group conversation (binary classification task), a dataset size of about 8.5K messages and a train-test-split of 75-25, the model achieves an f1-score of about 0.66.\n",
        "\n",
        "### Conclusion\n",
        "It seems likely that many text messages are simply too short (only a couple tokens long) to be effectively classified. Thus, I'm not sure if it is possible to achieve much higher scores, although tweaking and adding some more features is definitely possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFSm7eNaeli-",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "First, if necessary, install all dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FxwFTsObG-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install pandas\n",
        "# !pip install spacy\n",
        "# !pip install nltk\n",
        "# !pip install sklearn\n",
        "!pip install eli5\n",
        "!pip install emoji\n",
        "!pip install tensorflow-gpu==2.0.0-rc0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdbVP-2VBtRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from emoji import demojize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL000esgE5lA",
        "colab_type": "text"
      },
      "source": [
        "## Load WhatsApp chat protocol\n",
        "\n",
        "Load a WhatsApp chat protocol into the notebook.\n",
        "This is the raw file that gets created when exporting a conversation in WhatsApp."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BexdIXpNfGlU",
        "colab_type": "text"
      },
      "source": [
        "From local file system..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVSKURNHBwEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded_files = files.upload()\n",
        "\n",
        "# for name, file in uploaded_files.items():\n",
        "#     print(name, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIaW2YVWG6QN",
        "colab_type": "text"
      },
      "source": [
        "... or from Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fcZnuYVF3c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "path = \"/content/gdrive/My Drive/Analysis/WhatsApp/\"\n",
        "filename = input(\"Name of file: \")\n",
        "\n",
        "# Open file with specified name\n",
        "raw_protocol = list()\n",
        "with open(path + filename, 'r') as f:\n",
        "    \n",
        "    # For each line, split into timestamp, author and message body\n",
        "    for line in f:\n",
        "        splitted = re.compile(\"(.+) \\- (.+?): (.*)\").split(line)[1:-1]\n",
        "        if len(splitted) > 0:\n",
        "            splitted[-1] = demojize(splitted[-1])\n",
        "            raw_protocol.append(splitted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4cGSa5UG9Np",
        "colab_type": "text"
      },
      "source": [
        "### Process into Pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WdlF5W0GCQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "protocol = pd.DataFrame(raw_protocol)\n",
        "protocol.columns = [\"timestamp\", \"author\", \"body\"]\n",
        "protocol = protocol.dropna()\n",
        "protocol = protocol.reset_index(drop=True)\n",
        "\n",
        "# Print some information about the data\n",
        "print(\"Size: \", protocol.shape)\n",
        "protocol.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTz-uGARVf6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print all authors and class balance\n",
        "protocol.author.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGvIWtU7BSJu",
        "colab_type": "text"
      },
      "source": [
        "## Data analysis\n",
        "\n",
        "Let's look at time of day that the messages are sent at"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUn7WwhcBWps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def mins_since_midnight(timestamp):\n",
        "    date = datetime.strptime(timestamp, '%d/%m/%Y, %H:%M')\n",
        "    return date.time().hour * 60 + date.time().minute\n",
        "\n",
        "analysis = protocol.drop(\"timestamp\", axis=1)\n",
        "analysis[\"timestamp\"] = protocol[\"timestamp\"].apply(mins_since_midnight)\n",
        "\n",
        "print(\"Time of day of sent messages\")\n",
        "sns.violinplot(x=analysis[\"author\"], y=analysis[\"timestamp\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU3Lxm0gdOhC",
        "colab_type": "text"
      },
      "source": [
        "Plot the distribution of response times (time since previous message).\n",
        "\n",
        "Note that this is a naive implementation that does not account for new days."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUIJ3VAREZP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analysis[\"diff\"] = analysis[\"timestamp\"].diff().abs()\n",
        "diff = analysis[analysis[\"diff\"] < analysis[\"diff\"].quantile(0.86)]\n",
        "\n",
        "print(\"Time since previous message\")\n",
        "sns.violinplot(x=diff[\"author\"], y=diff[\"diff\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by0vRbJhOvAf",
        "colab_type": "text"
      },
      "source": [
        "## Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGpo_3GUOxXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "split = 0.25\n",
        "X_train, X_test, y_train, y_test = train_test_split(protocol.drop(\"author\", axis=1), \n",
        "                                                    protocol[\"author\"], \n",
        "                                                    test_size=split, \n",
        "                                                    shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAYgbOuaNNS9",
        "colab_type": "text"
      },
      "source": [
        "## Vectorization and Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TydHVblV4olE",
        "colab_type": "text"
      },
      "source": [
        "### Helper classes for pre-processing pipeline\n",
        "\n",
        "* Select column from pandas dataframe\n",
        "* Extract POS tags using spacy\n",
        "* Get time of day of message"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1R0awBH8u2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\" Select a series from pandas dataframe \"\"\"\n",
        "\n",
        "    def __init__(self, column_name):\n",
        "        self.column_name = column_name\n",
        "\n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        return df[self.column_name]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY80c9RJM-zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "class POSExtractor(BaseEstimator, TransformerMixin):\n",
        "    \"\"\" Extract POS tags using spaCy \"\"\"\n",
        "       \n",
        "    def __init__(self):\n",
        "        self.feature_names = set()\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "        self.nlp.remove_pipe('parser')\n",
        "        self.nlp.remove_pipe('ner')\n",
        "        print(\"Spacy POS model loaded.\")\n",
        "   \n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        pos_tags = []\n",
        "        for doc in self.nlp.pipe(df):\n",
        "            tokens = []\n",
        "            for token in doc:\n",
        "                self.feature_names.add(token.pos_)\n",
        "                tokens.append(token.pos_)\n",
        "            pos_tags.append(\" \".join(tokens))\n",
        "\n",
        "        return pd.Series(pos_tags)\n",
        "    \n",
        "    def get_feature_names(self):\n",
        "        return list(self.feature_names)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFBLK7oeNEXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class TimestampConverter(BaseEstimator, TransformerMixin):\n",
        "    \"\"\" Extract timestamps and convert to minute of day \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, x):\n",
        "\n",
        "        def mins_since_midnight(timestamp):\n",
        "            date = datetime.strptime(timestamp, '%d/%m/%Y, %H:%M')\n",
        "            return date.time().hour * 60 + date.time().minute\n",
        "        \n",
        "        times = pd.DataFrame(x.apply(mins_since_midnight))\n",
        "        return times\n",
        "    \n",
        "    # def get_feature_names(self):\n",
        "    #     return list(self.feature_names)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2mJS1IO4h4y",
        "colab_type": "text"
      },
      "source": [
        "### Classification pipelines\n",
        "\n",
        "Preprocessing pipeline can be reused for Keras later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4EnD_5gNvbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "vectorizer_params = {\n",
        "    \"ngram_range\": (1, 3),\n",
        "}\n",
        "\n",
        "token_vec = TfidfVectorizer(**vectorizer_params)\n",
        "pos_vec = TfidfVectorizer()\n",
        "ner_vec = TfidfVectorizer()\n",
        "\n",
        "# Define preprocessing pipeline\n",
        "preprocessing = Pipeline([\n",
        "    (\"features\", FeatureUnion([\n",
        "        (\"tokens\", Pipeline([\n",
        "            (\"select\", ColumnSelector(\"body\")),\n",
        "            (\"vec\", token_vec),\n",
        "        ])),\n",
        "        (\"pos_tags\", Pipeline([\n",
        "            (\"select\", ColumnSelector(\"body\")),\n",
        "            (\"extract\", POSExtractor()),\n",
        "            (\"vec\", pos_vec),\n",
        "        ])),\n",
        "        (\"time\", Pipeline([\n",
        "            (\"select\", ColumnSelector(\"timestamp\")),\n",
        "            (\"convert\", TimestampConverter()),\n",
        "            (\"disc\", KBinsDiscretizer(n_bins=24)),\n",
        "        ])),\n",
        "    ])),\n",
        "])\n",
        "\n",
        "# Add classifier\n",
        "model = make_pipeline(preprocessing, LinearSVC())\n",
        "\n",
        "# Dummy model as baseline\n",
        "dummy_model = make_pipeline(preprocessing, DummyClassifier(strategy=\"stratified\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ3ltDOGOplS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# Fit model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Fit dummy model\n",
        "dummy_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTdwkPwyUsCU",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WO4xpp2Ptqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Test data\")\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nTrain data\")\n",
        "y_pred = model.predict(X_train)\n",
        "print(classification_report(y_train, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT7KHwpll_Br",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Test data\")\n",
        "y_pred = dummy_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRMymcp2HHMx",
        "colab_type": "text"
      },
      "source": [
        "### Feature analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdXatLhnamWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import eli5\n",
        "\n",
        "features = token_vec.get_feature_names() + pos_vec.get_feature_names() + [\"[time_of_day]\"]*24\n",
        "eli5.show_weights(model.named_steps[\"linearsvc\"], feature_names=features, top=40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfs0ERxhT33m",
        "colab_type": "text"
      },
      "source": [
        "## Keras\n",
        "\n",
        "Create a multi-layer NN for author classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXa7k2EWTzZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "X_train_vec = preprocessing.fit_transform(X_train)\n",
        "X_test_vec = preprocessing.transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGGS0JNE7vzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "author_encoder = LabelBinarizer()\n",
        "\n",
        "y_train_n = author_encoder.fit_transform(y_train.to_frame())\n",
        "y_test_n = author_encoder.transform(y_test.to_frame())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbmJzvrSVsKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfmodel = tf.keras.Sequential()\n",
        "\n",
        "tfmodel.add(tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train_vec.shape[1], )))\n",
        "tfmodel.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "tfmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "          \n",
        "tfmodel.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoZ9GNb1XPDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfmodel.fit(x=X_train_vec,\n",
        "            y=y_train_n,\n",
        "            epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ati851bNs0Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Test\")\n",
        "print(classification_report(y_test_n, tfmodel.predict_classes(X_test_vec)))\n",
        "\n",
        "print(\"\\nTrain\")\n",
        "print(classification_report(y_train_n, tfmodel.predict_classes(X_train_vec)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaB0Y-i2X_pq",
        "colab_type": "text"
      },
      "source": [
        "## Playground (predict an author) (currently broken)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGZiL-LWVF70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from eli5.lime import TextExplainer\n",
        "te = TextExplainer(random_state=42)\n",
        "\n",
        "# Get message to predict\n",
        "input_message = input(\"Message to predict: \")\n",
        "\n",
        "# Convert to DataFrame, so it can be input into the pipeline\n",
        "input_df = pd.Series([input_message])\n",
        "\n",
        "print(\"This message is by %s with a probability of %f.\\n\" % (\n",
        "    pipeline.predict(input_df)[0], \n",
        "    max(pipeline.predict_proba(input_df)[0])\n",
        "))\n",
        "\n",
        "te.fit(input_message, model.predict_proba)\n",
        "te.show_prediction()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsJ8lsPIXK0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}